{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nulls in embarked\n",
    "df.dropna(subset=['embarked','embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pclass', 'sex','parch', \n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the \n",
    "le = LabelEncoder()\n",
    "df.loc[:,cols] = df.loc[:,cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y \n",
    "y = df['survived']\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the data using stratify to make sure we can get an even split of classes in the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = pd.DataFrame(ss.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002954791687186"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now with cross validation search\n",
    "val = cross_val_score(RandomForestClassifier(random_state=42),X_train,y_train,cv=5)\n",
    "val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"max_features\": [None,4,5,6,9,10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = RandomForestClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(rf_grid, rf_param_grid, cv=5, return_train_score=True, n_jobs=-1, verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3512 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5816 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8696 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12152 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 20792 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 25976 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
       "                         'max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=-1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 84.11%\n",
      "\n",
      "Optimal Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "Best Model: RandomForestClassifier(max_depth=10, max_features=5, min_samples_leaf=3,\n",
      "                       min_samples_split=10, n_estimators=10, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {:.4}%\".format(gridsearch.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(gridsearch.best_params_))\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(\"Best Model: {}\".format(gridsearch.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV * Number of params to search\n",
    "5*2*11*6*3*5*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our pipeline by passing a list of tuples with each class and its name in a string\n",
    "pipeline1 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to pipeline\n",
    "pipeline1.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy on test set\n",
    "pipeline1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the params, but we add a rf__ to each parameter to let it know its on the rf part of the pipeline\n",
    "rf_param_grid_pipe = {\n",
    "    \"rf__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"rf__max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"rf__max_features\": [None,4,5,6,9,10],\n",
    "    \"rf__min_samples_split\": [2, 5, 10],\n",
    "    \"rf__min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"rf__n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanstiate the gridsearch pipeline\n",
    "grid_search_pipe = GridSearchCV(pipeline2, rf_param_grid_pipe, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5940 candidates, totalling 29700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12052 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16852 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19552 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22452 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28852 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__criterion': ['gini', 'entropy'],\n",
       "                         'rf__max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14,\n",
       "                                           16],\n",
       "                         'rf__max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'rf__min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'rf__min_samples_split': [2, 5, 10],\n",
       "                         'rf__n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the grid search to the data\n",
    "grid_search_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8411110016743819\n",
      "{'rf__criterion': 'gini', 'rf__max_depth': 10, 'rf__max_features': 5, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 10, 'rf__n_estimators': 10}\n",
      "Pipeline(steps=[('ss', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=5,\n",
      "                                        min_samples_leaf=3,\n",
      "                                        min_samples_split=10, n_estimators=10,\n",
      "                                        random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_search_pipe.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_search_pipe.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_search_pipe.best_estimator_)\n",
    "#Identify the best score during fitting with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "#Predictions with grid search\n",
    "#Predict the response for test dataset\n",
    "y_pred = grid_search_pipe.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling the best Estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle list object\n",
    " \n",
    "model_pickle_path = 'best_model.pkl'\n",
    "\n",
    "#Create a variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(grid_search_pipe.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search\n",
    "\n",
    "Randomized Search allows us to search a distribution for each parameter instead of only a desginated value like GridSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.195254015709299, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Load in the Iris Dataset and the LogisticRegression class\n",
    "iris = load_iris()\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "# Set a distribution and options for the different parameters\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "#Fit and check the best parameters\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "- [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) (Documentation)\n",
    "\n",
    "- [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV) (Documentation)\n",
    "\n",
    "- [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) (Documentation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
